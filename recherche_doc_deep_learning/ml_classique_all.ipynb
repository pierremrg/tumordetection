{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"raw\": [],\n",
    "    \"cn\": [],\n",
    "    \"cna\": [],\n",
    "    \"cnacn\": []\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    \"raw\": [],\n",
    "    \"cn\": [],\n",
    "    \"cna\": [],\n",
    "    \"cnacn\": []\n",
    "}\n",
    "\n",
    "# TODO: Fix CNACN?\n",
    "del data[\"cnacn\"]\n",
    "del labels[\"cnacn\"]\n",
    "\n",
    "# Data paths\n",
    "DIRECTORY_RAW = '../images/data_raw/'\n",
    "DIRECTORY_CN = '../images/data_cn/'\n",
    "DIRECTORY_CNA = '../images/data_cna/'\n",
    "DIRECTORY_CNACN = '../images/data_cnacn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(directory, img_size = 0):\n",
    "    list_img = []\n",
    "    labels = []\n",
    "\n",
    "    for name in os.listdir(directory + 'yes'):\n",
    "        if name == \"Thumbs.db\":\n",
    "            continue\n",
    "        img = Image.open(directory + 'yes/'+ name)\n",
    "        if img_size != 0:\n",
    "            img = img.resize((img_size, img_size))\n",
    "        if directory == DIRECTORY_RAW:\n",
    "            img = img.convert('L').convert('RGB')\n",
    "        list_img.append(np.asarray(img).flatten())\n",
    "        labels.append(1)\n",
    "        \n",
    "    for name in os.listdir(directory + 'no'):\n",
    "        if name == \"Thumbs.db\":\n",
    "            continue\n",
    "        img = Image.open(directory + 'no/'+ name)\n",
    "        if img_size != 0:\n",
    "            img = img.resize((img_size, img_size))\n",
    "        if directory == DIRECTORY_RAW:\n",
    "            img = img.convert('L').convert('RGB')\n",
    "        list_img.append(np.asarray(img).flatten())\n",
    "        labels.append(0)\n",
    "\n",
    "    return list_img, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, '../webservices/crop/')\n",
    "from ImageCropper import ImageCropper\n",
    "\n",
    "sys.path.insert(1, '../webservices/data_augmentation/')\n",
    "from DataAugmentation import DataAugmentation\n",
    "\n",
    "sys.path.insert(1, '../webservices/normalization/')\n",
    "from ImageNormalizer import ImageNormalizer\n",
    "\n",
    "sys.path.insert(1, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crop + normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../images/data_cn/ already exists\n",
      "../images/data_cn/yes already exists\n",
      "../images/data_cn/no already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:33:42 - DEBUG - STREAM b'IHDR' 16 13\n",
      "20:33:42 - DEBUG - STREAM b'IDAT' 41 8192\n",
      "20:33:43 - DEBUG - STREAM b'IHDR' 16 13\n",
      "20:33:43 - DEBUG - STREAM b'IDAT' 41 8192\n"
     ]
    }
   ],
   "source": [
    "imc2 = ImageCropper(DIRECTORY_RAW, DIRECTORY_CN, ['yes', 'no'])\n",
    "imc2.createOutputDirectory()\n",
    "imc2.cropImages()\n",
    "\n",
    "imgnorm2 = ImageNormalizer(DIRECTORY_CN, DIRECTORY_CN)\n",
    "imgnorm2.loadImagesData()\n",
    "imgnorm2.resizeImages(\n",
    "    mode = ImageNormalizer.MODE_RESIZING_KEEP_RATIO,\n",
    "    background_color = 'black',\n",
    "    shape = ImageNormalizer.SHAPE_SQUARE,\n",
    "    square_size = 1000\n",
    ")\n",
    "imgnorm2.convertImages2GrayscaleMode()\n",
    "imgnorm2.convertImages2RGBMode()\n",
    "imgnorm2.saveImages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crop + normalized + data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20:33:58 - INFO - data_augmentation.init\n",
      "20:33:58 - INFO - ../images/data_cna/ already exists\n",
      "20:33:58 - INFO - ../images/data_cna/yes already exists\n",
      "20:33:58 - INFO - ../images/data_cna/no already exists\n",
      "20:34:06 - INFO - data_augmentation.equilibrate\n",
      "20:34:06 - INFO - data_augmentation.compute_equilibrate\n",
      "20:34:06 - INFO - Adding 57 images to ../images/data_cna/no/\n",
      "20:34:06 - INFO - data_augmentation.compute_flip\n",
      "20:34:08 - INFO - data_augmentation.augmentation\n",
      "20:34:08 - INFO - data_augmentation.perform_rotate\n",
      "20:34:08 - INFO - data_augmentation.apply_filters\n"
     ]
    }
   ],
   "source": [
    "da = DataAugmentation(DIRECTORY_CN, max_augmentation=1000, directory_to=DIRECTORY_CNA)\n",
    "da.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img, list_labels = read_images(DIRECTORY_RAW, 240)\n",
    "data[\"raw\"] = list_img\n",
    "labels[\"raw\"] = list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to dictionnary\n",
    "list_img, list_labels = read_images(DIRECTORY_CN, 240)\n",
    "data[\"cn\"] = list_img\n",
    "labels[\"cn\"] = list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to dictionnary\n",
    "list_img, list_labels = read_images(DIRECTORY_CNA, 240)\n",
    "data[\"cna\"] = list_img\n",
    "labels[\"cna\"] = list_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_best(args):\n",
    "    (xtrain, xtest, ytrain, ytest) = args\n",
    "    max_score = 0\n",
    "    for k in range(2, 20):\n",
    "        clf = KNeighborsClassifier(n_neighbors=k, n_jobs=-1)\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        score = clf.score(xtest, ytest)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_k = k\n",
    "       \n",
    "    return max_score, max_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-941614f332f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mlist_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_best\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Max score using %s: %.4f with %d neighbors\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-a53f0adcb4a7>\u001b[0m in \u001b[0;36mknn_best\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    255\u001b[0m             self._tree = KDTree(X, self.leaf_size,\n\u001b[0;32m    256\u001b[0m                                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                                 **self.effective_metric_params_)\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'brute'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for key in data:        \n",
    "    list_img = data[key]\n",
    "    list_labels = labels[key]\n",
    "    \n",
    "    score, k = knn_best( train_test_split(list_img, list_labels, test_size=0.2) )\n",
    "    print(\"Max score using %s: %.4f with %d neighbors\" %(key, score, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max score using raw: 0.7925\n",
      "Max score using cn: 0.7900\n",
      "Max score using cna: 0.7850\n"
     ]
    }
   ],
   "source": [
    "for key in data:       \n",
    "    list_img = data[key]\n",
    "    list_labels = labels[key]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(list_img, list_labels, test_size=0.2)\n",
    "    \n",
    "    gbc = GradientBoostingClassifier(n_estimators=50)\n",
    "    gbc.fit(xtrain, ytrain)\n",
    "    score = gbc.score(xtest, ytest)\n",
    "    print(\"Max score using %s: %.4f\" %(key, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Max score using raw: 0.7925\n",
    " - Max score using cn: 0.7900\n",
    " - Max score using cna: 0.7850"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max score using raw: 0.8816\n",
      "Max score using cn: 0.6974\n",
      "Max score using cna: 0.8433\n"
     ]
    }
   ],
   "source": [
    "for key in data:\n",
    "    list_img = data[key]\n",
    "    list_labels = labels[key]\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(list_img, list_labels, test_size=0.3)    \n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators=2000, n_jobs=-1)\n",
    "    rfc.fit(xtrain, ytrain)\n",
    "    score = rfc.score(xtest, ytest)\n",
    "    print(\"Max score using %s: %.4f\" %(key, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Max score using raw: 0.8816\n",
    " - Max score using cn: 0.6974\n",
    " - Max score using cna: 0.8433"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY_RAW = \"../images/dataset/\"\n",
    "imgs, lbls = read_images(DIRECTORY_RAW, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  9.4min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "  verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'kernel': ['poly', 'linear', 'rbf', 'sigmoid']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "svm = SVC(gamma='auto', random_state=0, probability=True)\n",
    "grid = {\n",
    "    'kernel': ['poly', 'linear', 'rbf', 'sigmoid']\n",
    "}\n",
    "gs = GridSearchCV(svm, grid, verbose=2, cv=5, n_jobs=-1)\n",
    "gs.fit(imgs, lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'poly'}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 1. 1. ... 7. 7. 7.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-18e87b4552f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlbls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \"\"\"\n\u001b[1;32m--> 576\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \"\"\"\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=np.float64, order=\"C\",\n\u001b[1;32m--> 458\u001b[1;33m                         accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    550\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 1. 1. ... 7. 7. 7.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "p = gs.best_params_\n",
    "print(p)\n",
    "svm = SVC(**p, gamma='auto', random_state=0, probability=True)\n",
    "svm.fit(imgs, lbls)\n",
    "print(svm.predict(imgs[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_SVM(args):\n",
    "    (xtrain, xtest, ytrain, ytest) = args\n",
    "    best_score = 0\n",
    "\n",
    "    for k in ('poly', 'linear', 'rbf', 'sigmoid'):\n",
    "        print(\"Testing %s kernel..\" %(k))\n",
    "        svm = SVC(kernel=k, gamma='auto')\n",
    "        svm.fit(xtrain, ytrain)\n",
    "        score = svm.score(xtest,ytest)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_kernel = k\n",
    "    \n",
    "    return best_score, best_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "svm = SVC(gamma='auto', random_state=0, probability=True)\n",
    "grid = {\n",
    "    'kernel' = ['poly', 'linear', 'rbf', 'sigmoid']\n",
    "    'C' = [10**-4, 10**-2, 1, 10]\n",
    "}\n",
    "GridSearchCV(svm, grid, verbose=2, cv=2, n_jobs=-1).fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing poly kernel..\n",
      "Testing linear kernel..\n",
      "Testing rbf kernel..\n",
      "Testing sigmoid kernel..\n",
      "Max score using raw: 0.8026 with poly kernel\n",
      "Testing poly kernel..\n",
      "Testing linear kernel..\n",
      "Testing rbf kernel..\n",
      "Testing sigmoid kernel..\n",
      "Max score using cn: 0.6447 with linear kernel\n",
      "Testing poly kernel..\n",
      "Testing linear kernel..\n",
      "Testing rbf kernel..\n",
      "Testing sigmoid kernel..\n",
      "Max score using cna: 0.7517 with poly kernel\n"
     ]
    }
   ],
   "source": [
    "for key in data:\n",
    "    list_img = data[key]\n",
    "    list_labels = labels[key]\n",
    "    score, kernel = best_SVM( train_test_split(list_img, list_labels, test_size=0.3) )\n",
    "    print(\"Max score using %s: %.4f with %s kernel\" %(key, score, kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Max score using raw: 0.8026 with poly kernel\n",
    " - Max score using cn: 0.6447 with linear kernel\n",
    " - Max score using cna: 0.7517 with poly kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data compression\n",
    "Data is reloaded but with the size of the images set to **32x32x3** (RBG)\n",
    "This reduces the size of the input layer to **3084 nodes** instead of 127800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_img, list_labels = read_images(DIRECTORY_RAW, 64)\n",
    "data[\"raw\"] = list_img\n",
    "labels[\"raw\"] = list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to dictionnary\n",
    "list_img, list_labels = read_images(DIRECTORY_CN, 64)\n",
    "data[\"cn\"] = list_img\n",
    "labels[\"cn\"] = list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to dictionnary\n",
    "list_img, list_labels = read_images(DIRECTORY_CNA, 64)\n",
    "data[\"cna\"] = list_img\n",
    "labels[\"cna\"] = list_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_nn(args):\n",
    "    (xtrain, xtest, ytrain, ytest) = args\n",
    "    best_score = 0\n",
    "    nb_nodes = [32, 64, 128, 256] # Number of nodes per hidden layer\n",
    "    nb_layers = [2,10,50,100] # Number of hidden layers\n",
    "    \n",
    "    for nb_node in nb_nodes:\n",
    "        for nb_layer in nb_layers:\n",
    "            print(\"Testing %d layers of %d nodes..\" %(nb_layer, nb_node))\n",
    "            nn = neural_network.MLPClassifier(hidden_layer_sizes=tuple([nb_node for i in range(nb_layer)]) )\n",
    "            nn.fit(xtrain, ytrain)\n",
    "            score = nn.score(xtest, ytest)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_node = nb_node\n",
    "                best_layer = nb_layer\n",
    "            \n",
    "    return best_score, best_node, best_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 2 layers of 32 nodes..\n",
      "Testing 10 layers of 32 nodes..\n",
      "Testing 50 layers of 32 nodes..\n",
      "Testing 100 layers of 32 nodes..\n",
      "Testing 2 layers of 64 nodes..\n",
      "Testing 10 layers of 64 nodes..\n",
      "Testing 50 layers of 64 nodes..\n",
      "Testing 100 layers of 64 nodes..\n",
      "Testing 2 layers of 128 nodes..\n",
      "Testing 10 layers of 128 nodes..\n",
      "Testing 50 layers of 128 nodes..\n",
      "Testing 100 layers of 128 nodes..\n",
      "Testing 2 layers of 256 nodes..\n",
      "Testing 10 layers of 256 nodes..\n",
      "Testing 50 layers of 256 nodes..\n",
      "Testing 100 layers of 256 nodes..\n",
      "Max score using raw: 0.8158 with 128 layers of size 2\n",
      "Testing 2 layers of 32 nodes..\n",
      "Testing 10 layers of 32 nodes..\n",
      "Testing 50 layers of 32 nodes..\n",
      "Testing 100 layers of 32 nodes..\n",
      "Testing 2 layers of 64 nodes..\n",
      "Testing 10 layers of 64 nodes..\n",
      "Testing 50 layers of 64 nodes..\n",
      "Testing 100 layers of 64 nodes..\n",
      "Testing 2 layers of 128 nodes..\n",
      "Testing 10 layers of 128 nodes..\n",
      "Testing 50 layers of 128 nodes..\n",
      "Testing 100 layers of 128 nodes..\n",
      "Testing 2 layers of 256 nodes..\n",
      "Testing 10 layers of 256 nodes..\n",
      "Testing 50 layers of 256 nodes..\n",
      "Testing 100 layers of 256 nodes..\n",
      "Max score using cn: 0.7237 with 128 layers of size 2\n",
      "Testing 2 layers of 32 nodes..\n",
      "Testing 10 layers of 32 nodes..\n",
      "Testing 50 layers of 32 nodes..\n",
      "Testing 100 layers of 32 nodes..\n",
      "Testing 2 layers of 64 nodes..\n",
      "Testing 10 layers of 64 nodes..\n",
      "Testing 50 layers of 64 nodes..\n",
      "Testing 100 layers of 64 nodes..\n",
      "Testing 2 layers of 128 nodes..\n",
      "Testing 10 layers of 128 nodes..\n",
      "Testing 50 layers of 128 nodes..\n",
      "Testing 100 layers of 128 nodes..\n",
      "Testing 2 layers of 256 nodes..\n",
      "Testing 10 layers of 256 nodes..\n",
      "Testing 50 layers of 256 nodes..\n",
      "Testing 100 layers of 256 nodes..\n",
      "Max score using cna: 0.7183 with 128 layers of size 10\n"
     ]
    }
   ],
   "source": [
    "for key in data:\n",
    "    list_img = data[key]\n",
    "    list_labels = labels[key]\n",
    "    score, nodes, layers = best_nn( train_test_split(list_img, list_labels, test_size=0.3) )\n",
    "    print(\"Max score using %s: %.4f with %d layers of size %d\" %(key, score, nodes, layers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using a size of 32x32x3\n",
    "\n",
    "- Max score using raw: 0.8421 with 10 layers of size 64\n",
    "- Max score using cn: 0.7895 with 10 layers of size 32\n",
    "- Max score using cna: 0.7700 with 10 layers of size 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using a size of 64x64x3\n",
    " - Max score using raw: 0.8158 with 128 layers of size 2\n",
    " - Max score using cn: 0.7237 with 128 layers of size 2\n",
    " - Max score using cna: 0.7183 with 128 layers of size 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
